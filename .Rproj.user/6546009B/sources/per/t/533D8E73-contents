---
title: "Training a Machine Learning algorithm on Human Excercise data"
output:
  pdf_document: default
  html_notebook: default
---

# Introduction
For this project, I was asked to train a Machine Learning algorithm to identify the type of excercise being done using data from various wearable sensors. 

# Exploratory Data Analysis
We begin by loading the data and the necessary libraries and setting a seed to allow for reproducibility:

```{r}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
library(caret); library(ggplot2); library(janitor); library(e1071)
set.seed(24051998)
```

We can see that there are some unnecessary variables , we proceed by cleansing both the training and testing data sets:

```{r}
unn_vars <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","problem_id")
training <- training[,-which(names(training) %in% unn_vars)]
testing <- testing[,-which(names(testing) %in% unn_vars)]
training <- training[,-grep("^var|^std|^avg|^kurtosis|^skewness|^amplitude|^max|^min",names(training))]
testing <- testing[,-grep("^var|^std|^avg|^kurtosis|^skewness|^amplitude|^max|^min",names(testing))]
```

We factorize the *new_window* and the *classe* variables and create a validation data set:

```{r}
training$new_window <- as.factor(training$new_window)
training$classe <- as.factor(training$classe)
testing$new_window <- as.factor(testing$new_window)
inTrain <- createDataPartition(training$classe, p = 0.7, list = F)
training <- training[inTrain,]
validation <- training[-inTrain,]
```

The structure of the data:

```{r}
head(training)
```
```{r}
str(training)
```

The unique values to be predicted are:

```{r}
unique(training$classe)
```

As we can see after the cleansing, the training data is comprised of 55 variables and 13737 observations.

# Model Fitting
In this project we will try to fit 5 different models and validate/combine them to reach a good enough accuracy. The models we will use are:

* Random Forests
* Linear Discriminant Analysis
* Naive Bayes
* Boosting with Trees
* Support Vector Machine
* Combination of all of them

## Random Forests
We fit the model:

```{r}
model_rf <- train(classe ~ ., model = "rf", data = training)
model_rf$finalModel
```

Then predict on the testing data set:

```{r}
predict_rf <- predict(model_rf, validation)
head(predict_rf)
```

The accuracy for this model is:

```{r}
confusionMatrix(predict_rf, validation$classe)$overall
```


## Linear Dsicriminant Analysis
We begin by fitting the model

```{r}
model_lda <- train(classe ~ ., model = "lda", data = training)
model_lda$finalModel
```

Then predict on the testing data set:

```{r}
predict_lda <- predict(model_lda, validation)
head(predict_lda)
```

The accuracy for this model is:

```{r}
confusionMatrix(predict_lda, validation$classe)$overall
```

## Naive Bayes
We begin by fitting the model

```{r}
model_nb <- train(classe ~ ., model = "nb", data = training)
model_nb$finalModel
```

Then predict on the testing data set:

```{r}
predict_nb <- predict(model_nb, validation)
head(predict_nb)
```

The accuracy for this model is:

```{r}
confusionMatrix(predict_nb, validation$classe)$overall
```

## Boosting with Trees
We begin by fitting the model

```{r}
model_gbm <- train(classe ~ ., model = "gbm", data = training)
model_gbm$finalModel
```

Then predict on the testing data set:

```{r}
predict_gbm <- predict(model_gbm, validation)
head(predict_gbm)
```

The accuracy for this model is:

```{r}
confusionMatrix(predict_gbm, validation$classe)$overall
```

## Support Vector Machine
We begin by fitting the model

```{r}
model_svm <- svm(classe ~ ., data = training)
model_svm
```

Then predict on the testing data set:

```{r}
predict_svm <- predict(model_svm, validation)
head(predict_svm)
```

The accuracy for this model is:

```{r}
confusionMatrix(predict_svm, validation$classe)$overall
```

## Combination
Since we now have all four models, we can use a combination of all using Random Forests once again to get a better accuracy:

```{r}
df_all <- data.frame(predict_rf, predict_lda, predict_nb, predict_gbm, predict_svm, classe = validation$classe)
model_all <- train(classe ~ ., method = "rf", data = df_all)
model_all$finalModel
```

Now we try to predict once again using this new model:

```{r}
predict_all <- predict(model_all, validation)
head(predict_all)
```

With this accuracy:

```{r}
confusionMatrix(predict_all, validation$classe)$overall
```

## Predictions on Test data set
Since all models have a high accuracy, we will proceed to use only the Random Forest model to try to predict the results on the test set, which will be used on the quiz:

```{r}
predict_test <- predict(model_rf,testing)
predict_test
```

# Appendix
Plot of the Random Forest model:

```{r}
plot(model_rf)
```

Plot of the General Boosted Trees model:

```{r}
plot(model_gbm)
```

Plot of the Linear Discriminant Analysis model:

```{r}
plot(model_lda)
```

Plot of the Naive Bayes model:

```{r}
plot(model_nb)
```